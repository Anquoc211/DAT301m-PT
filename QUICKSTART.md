# Quick Start Guide

## Running the Solution

### 1. **Install Dependencies** (if not already done)
```bash
cd "C:\Users\Admin\Desktop\DAT301m PT"
.\.venv\Scripts\pip install numpy pandas scikit-learn xgboost lightgbm scipy
```

### 2. **Run the Solution**
```bash
cd "C:\Users\Admin\Desktop\DAT301m PT"
.\.venv\Scripts\python.exe main.py
```

**Expected output:**
- `Dataset/submission.csv` – Test predictions (5,206 rows × 2 columns)
- Console output – Validation metrics, classification report
- Runtime: ~16 minutes (CPU-based, single machine)

### 3. **Check Results**
```bash
# View submission file
head -5 Dataset/submission.csv

# Expected output:
# ID,TARGET
# 0,1
# 1,0
# 2,4
# ...
```

---

## File Structure

```
DAT301m PT/
├── main.py                    ← Main solution (run this)
├── README.md                  ← Detailed documentation
├── QUICKSTART.md              ← This file
├── Dataset/
│   ├── X_train.npy           ← Training features (9,716 samples)
│   ├── X_val.npy             ← Validation features (2,429 samples)
│   ├── X_test.npy            ← Test features (5,206 samples)
│   ├── y_train.npy           ← Training labels (9,716 labels)
│   ├── y_val.npy             ← Validation labels (2,429 labels)
│   └── submission.csv        ← Output (generated by main.py)
└── .venv/                    ← Virtual environment
```

---

## Key Parameters (in `main.py`)

Edit these to experiment:

```python
# Line 50: Number of base models
base_models = [...]  # Currently 5 models
# Add/remove models to change ensemble diversity

# Line 58: Number of K-fold splits
n_splits = 5  # Try 3, 10, etc.
# More folds = better meta-features but slower training

# Line ~100+: Base model hyperparameters
# Adjust learning_rate, max_depth, subsample, etc.

# Line ~150: Meta-learner type
meta_learner = XGBClassifier(...)
# Try: LGBMClassifier, GradientBoostingClassifier, etc.
```

---

## Understanding the Output

### Console Output Example:
```
Loading data...
Extracting features...
Features: 115

STACKING WITH 5 BASE MODELS + WEIGHTED SOFT VOTING
Fold 1/5... done
Fold 2/5... done
...
Fold 5/5... done

Training meta-learner...
Stacking F1-Macro: 0.878, Accuracy: 0.91
Weighted Soft Voting F1-Macro: 0.875, Accuracy: 0.91

>>> Using Stacking for submission (F1-Macro: 0.878)

CLASSIFICATION REPORT
              precision    recall  f1-score  support
     Class 0       1.00     1.00     1.00    1094
     ...
Submission: 5206 rows saved
Expected F1-Macro: 0.878
```

### Submission CSV Format:
```
ID,TARGET
0,1
1,0
2,4
3,0
4,0
...
5205,2
```
- **ID:** Sample index (0-5205)
- **TARGET:** Predicted class (0-7)

---

## Expected Performance

| Metric | Value |
|--------|-------|
| Validation F1-Macro | 0.878+ |
| Validation Accuracy | 0.91+ |
| Test Accuracy (Leaderboard) | 0.92 |
| Runtime | ~16 minutes |

**Note:** Exact values vary slightly due to random seeds (KFold shuffle).

---

## Troubleshooting

### Error: `ModuleNotFoundError: No module named 'xgboost'`
```bash
.\.venv\Scripts\pip install xgboost lightgbm
```

### Error: `File not found: X_train.npy`
- Ensure `Dataset/` folder contains all `.npy` files
- Check dataset path in `main.py` line 24

### Slow Training
- Reduce `n_splits` from 5 to 3
- Reduce `n_estimators` in base models
- Use GPU (LightGBM supports CUDA acceleration)

### Memory Issues
- Reduce number of base models
- Use smaller `n_estimators` values

---

## Advanced Usage

### Experiment 1: Test Different Meta-Learner
```python
# In main.py, line ~150:
# Change from:
meta_learner = XGBClassifier(n_estimators=200, max_depth=6, learning_rate=0.08, random_state=42, verbosity=0)

# To:
meta_learner = LGBMClassifier(n_estimators=200, max_depth=6, learning_rate=0.08, random_state=42, verbose=-1)
```

### Experiment 2: Adjust Number of Folds
```python
# Line 58:
n_splits = 10  # More folds = better but slower
```

### Experiment 3: Add Custom Model
```python
# Line ~50, add to base_models:
from sklearn.svm import SVC

base_models = [
    ...,
    ('SVM', SVC(kernel='rbf', probability=True, random_state=42))
]
```

---

## Interpretation Guide

### Why Stacking Works
1. **Diversity:** 5 different models capture different patterns
2. **No Leakage:** K-fold CV prevents data leakage
3. **Meta-Learning:** Meta-learner learns optimal combination
4. **Regularization:** Each base model regularized independently

### Why Weighted Soft Voting Matters
- **Fallback:** If stacking overfits, soft voting is more stable
- **Interpretability:** Can see which models contribute most
- **Robustness:** Equal voting = baseline, weighted voting = improvement

### Class Imbalance Solution
- **Class weights:** Minority classes get 3-5x higher weight
- **Metrics:** F1-Macro treats all classes equally (vs. Accuracy)
- **Feature engineering:** Diverse features help rare classes

---

## Next Steps

1. **Submit** `Dataset/submission.csv` to leaderboard
2. **Compare** your submission with baseline
3. **Experiment** with hyperparameters (see "Advanced Usage" above)
4. **Read** README.md for detailed technical explanation

---

## Questions?

Refer to:
- **Technical Details:** README.md
- **Code Comments:** main.py (well-commented)
- **Paper References:** README.md > References section
